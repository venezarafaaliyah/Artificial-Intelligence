{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamClassification",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5yP2s5MQ8g0",
        "outputId": "08ecb992-b45a-4bbf-bb21-36bdc2f35d76"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "aeeplns2XLw3",
        "outputId": "ab88775c-e791-4b95-e476-3fa15b0e9974"
      },
      "source": [
        "# Loading the spam data\n",
        "# ham is the label for non-spam messages\n",
        "spam = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/spam.csv')\n",
        "spam.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
              "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
              "6   ham  Even my brother is not like to speak with me. ...\n",
              "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
              "8  spam  WINNER!! As a valued network customer you have...\n",
              "9  spam  Had your mobile 11 months or more? U R entitle..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYaJ0kywoz2d"
      },
      "source": [
        "spaCy handles the bag of words conversion and building a simple linear model for you with the TextCategorizer class.The TextCategorizer is a spaCy pipe. Pipes are classes for processing and transforming tokens.\n",
        "\n",
        "You can remove or add pipes to models. What we'll do here is create an empty model without any pipes (other than a tokenizer, since all models always have a tokenizer). Then, we'll create a TextCategorizer pipe and add it to the empty model.\n",
        "\n",
        "Since the classes are either ham or spam, we set \"exclusive_classes\" to True.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI4eP-HMjE7R",
        "outputId": "6c9c4b29-59a0-4a2d-d198-381264429bf6"
      },
      "source": [
        "import spacy\n",
        "# Create an empty model\n",
        "nlp = spacy.blank(\"en\")\n",
        "# Create the TextCategorizer with exclusive classes and \"bow\" architecture\n",
        "textcat = nlp.create_pipe(\n",
        "              \"textcat\",\n",
        "              config={\n",
        "                \"exclusive_classes\": True,\n",
        "                \"architecture\": \"bow\"})\n",
        "# Add the TextCategorizer to the empty model\n",
        "nlp.add_pipe(textcat)\n",
        "# Add labels to text classifier\n",
        "textcat.add_label(\"ham\")\n",
        "textcat.add_label(\"spam\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX2wif9PjgOf"
      },
      "source": [
        "Since the classes are either ham or spam, we set \"exclusive_classes\" to True. \"bow\" stands for Bag of Words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYkAo35Mj7Pz",
        "outputId": "816ed9d2-e5e7-45b7-c1d3-f2d2409586d3"
      },
      "source": [
        "train_texts = spam['text'].values\n",
        "train_labels = [{'cats': {'ham': label == 'ham',\n",
        "              'spam': label == 'spam'}} \n",
        "                for label in spam['label']]\n",
        "                \n",
        "# The zip() function returns an iterator of tuples based on the iterable objects\n",
        "# zip(['a', 'b', 'c'], [1, 2, 3]) yields ('a', 1) ('b', 2) ('c', 3)\n",
        "train_data = list(zip(train_texts, train_labels))\n",
        "train_data[:3]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
              "  {'cats': {'ham': True, 'spam': False}}),\n",
              " ('Ok lar... Joking wif u oni...', {'cats': {'ham': True, 'spam': False}}),\n",
              " (\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
              "  {'cats': {'ham': False, 'spam': True}})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r94ZtLQGuim1"
      },
      "source": [
        "create an optimizer using nlp.begin_training(). spaCy uses this optimizer to update the model. In general it's more efficient to train models in small batches. spaCy provides the minibatch function that returns a generator yielding minibatches for training. Finally, the minibatches are split into texts and labels, then used with nlp.update to update the model's parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpKZq_4bk6uF"
      },
      "source": [
        "from spacy.util import minibatch\n",
        "\n",
        "spacy.util.fix_random_seed(1)\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "# Create the batch generator with batch size = 8\n",
        "batches = minibatch(train_data, size=8)\n",
        "# Iterate through minibatches\n",
        "for batch in batches:\n",
        "    # Each batch is a list of (text, label) but we need to\n",
        "    # send separate lists for texts and labels to update().\n",
        "    # This is a quick way to split a list of tuples into lists\n",
        "    # In python, * is the 'splat' operator. It is used for unpacking a list into arguments. \n",
        "    # For example: foo(*[1, 2, 3]) is the same as foo(1, 2, 3).\n",
        "    \n",
        "    texts, labels = zip(*batch)   \n",
        "    nlp.update(texts, labels, sgd=optimizer)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WIE20xVqOt0"
      },
      "source": [
        "This is just one training loop (or epoch) through the data. The model will typically need multiple epochs. Use another loop for more epochs, and optionally re-shuffle the training data at the begining of each loop.\n",
        "\n",
        "print(loss) shows the accumulated losses of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGtjXtBglDyd",
        "outputId": "eda016bf-0fbe-4459-b5b9-cfa46988c2b8"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(1)\n",
        "spacy.util.fix_random_seed(1)\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "losses = {}\n",
        "for epoch in range(10):\n",
        "    random.shuffle(train_data)\n",
        "    # Create the batch generator with batch size = 8\n",
        "    batches = minibatch(train_data, size=8)\n",
        "    # Iterate through minibatches\n",
        "    for batch in batches:\n",
        "        # Each batch is a list of (text, label) but we need to\n",
        "        # send separate lists for texts and labels to update().\n",
        "        # This is a quick way to split a list of tuples into lists\n",
        "        texts, labels = zip(*batch)\n",
        "        nlp.update(texts, labels, sgd=optimizer, losses=losses)\n",
        "    print(losses)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'textcat': 0.43189741921099767}\n",
            "{'textcat': 0.6474976215331196}\n",
            "{'textcat': 0.7842154536487618}\n",
            "{'textcat': 0.8716683716818165}\n",
            "{'textcat': 0.9280939335008995}\n",
            "{'textcat': 0.9655779922872296}\n",
            "{'textcat': 0.9939651840090362}\n",
            "{'textcat': 1.0127976631523663}\n",
            "{'textcat': 1.0275637812859075}\n",
            "{'textcat': 1.0378531470013608}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs44Zxxiu3DK"
      },
      "source": [
        "Now that you have a trained model, you can make predictions with the predict() method. The input text needs to be tokenized with nlp.tokenizer. Then you pass the tokens to the predict method which returns scores. The scores are the probability the input text belongs to the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8en01cumV6X",
        "outputId": "f714a90e-7dd9-4f91-e1aa-3ca2ee0a4803"
      },
      "source": [
        "texts = [\"Are you ready for the tea party????? It's gonna be wild\",\n",
        "         \"URGENT Reply to this message for GUARANTEED FREE TEA\",\n",
        "         \"This is the tea I like, would you like to try it out\",\n",
        "         \"Tea for sale. Have a 30% off by the end of Auguest\"\n",
        "         ]\n",
        "docs = [nlp.tokenizer(text) for text in texts]\n",
        "    \n",
        "# Use textcat to get the scores for each doc\n",
        "textcat = nlp.get_pipe('textcat')\n",
        "scores, _ = textcat.predict(docs)\n",
        "\n",
        "print(scores.round(3))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.    0.   ]\n",
            " [0.011 0.989]\n",
            " [0.966 0.034]\n",
            " [0.856 0.144]\n",
            " [0.757 0.243]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}