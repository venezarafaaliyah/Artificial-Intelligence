{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spacyNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-Jxl2qkwMj2"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(\"Tea is healthy and calming, don't you think?\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UupynFVHwZ4l"
      },
      "source": [
        "Tokenizing\n",
        "\n",
        "This returns a document object that contains tokens. A token is a unit of text in the document, such as individual words and punctuation. SpaCy splits contractions like \"don't\" into two tokens, \"do\" and \"n't\". You can see the tokens by iterating through the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvZJYltPwm12"
      },
      "source": [
        "for token in doc:\n",
        "    print(token)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdlY6NxCw3Hk"
      },
      "source": [
        "Text preprocessing\n",
        "With a spaCy token, token.lemma_ returns the lemma, while token.is_stop returns a boolean True if the token is a stopword (and False otherwise)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Cxs5Zv5w-tm"
      },
      "source": [
        "print(f\"Token \\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\n",
        "print(\"-\"*40)\n",
        "for token in doc:\n",
        "    print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdAKbhGB0_xM"
      },
      "source": [
        "token.dep_: Syntactic dependency relation.\n",
        "\n",
        "token.pos_: Coarse-grained part-of-speech from the Universal POS tag set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUKaI0rl0jfV"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAzrDmSo13OW",
        "outputId": "ac760088-676e-4a8f-bfdb-8edd5fe14ec5"
      },
      "source": [
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text}\\t\\t {ent.start_char}\\t\\t {ent.end_char}\\t\\t{ent.label_}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple\t\t 0\t\t 5\t\tORG\n",
            "U.K.\t\t 27\t\t 31\t\tGPE\n",
            "$1 billion\t\t 44\t\t 54\t\tMONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO0ME0Tc3Jkl"
      },
      "source": [
        "Similarity is based on cosine function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m36exT83Ks9"
      },
      "source": [
        "import spacy\n",
        "\n",
        "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
        "doc2 = nlp(\"Fast food tastes very good.\")\n",
        "\n",
        "# Similarity of two documents\n",
        "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}